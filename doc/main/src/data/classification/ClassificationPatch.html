<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>main.src.data.classification.ClassificationPatch API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>main.src.data.classification.ClassificationPatch</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from functools import lru_cache
from typing import Tuple, List, Union
import numpy as np
import psutil

from main.FolderInfos import FolderInfos
from main.src.data.TwoWayDict import  Way
from main.src.data.balance_classes.balance_classes import BalanceClasses1
from main.src.data.balance_classes.no_balance import NoBalance
from main.src.data.patch_creator.patch_creator0 import Patch_creator0
from main.src.data.resizer import Resizer
from main.src.data.segmentation.DataSentinel1Segmentation import DataSentinel1Segmentation
import time
from rasterio.transform import Affine,rowcol


class ClassificationPatch(DataSentinel1Segmentation):
    def __init__(self, patch_creator: Patch_creator0, input_size: int = None,
                 limit_num_images: int = None, balance=&#34;nobalance&#34;,margin=None):
        &#34;&#34;&#34;Class that adapt the inputs from the hdf5 file (input image, label image), and manage other objects to create patches,
        filteer them.

        Args:
            patch_creator: the object of PatchCreator0 class managing patches
            input_size: the size of the image provided as input to the model ⚠️
            limit_num_images: limit the number of image in the dataset per epoch (before filtering)
            balance: str enum {nobalance,balance} indicating the class used to balance images
            margin: opt int, argument for the BalanceClass1 class
        &#34;&#34;&#34;
        self.attr_name = self.__class__.__name__ # save the name of the class used for reproductibility purposes
        self.patch_creator = patch_creator
        self.attr_limit_num_images = limit_num_images
        self.attr_resizer = Resizer(out_size_w=input_size)
        super(ClassificationPatch, self).__init__(limit_num_images, input_size=input_size)
        self.attr_global_name = &#34;dataset&#34;
        if balance == &#34;nobalance&#34;:
            self.attr_balance = NoBalance()
        elif balance == &#34;balanceclasses1&#34;:
            # see class DataSentinel1Segmentation for documentation on attr_class_mapping storage and access to values
            self.attr_balance = BalanceClasses1(classes_indexes=self.attr_class_mapping.keys(Way.ORIGINAL_WAY),
                                                margin=margin)


    @lru_cache(maxsize=1)
    def get_all_items(self):
        &#34;&#34;&#34;List available original images available in the dataset (hdf5 file)
        the :lru_cache(maxsize=1) allow to compute it only one time and store the result in a cache

        Allow to limit the number of original image used in the dataset

        Returns: list of list of str,int: [[img_uniq_id,id_patch],...]

        &#34;&#34;&#34;
        list_items = []
        for img_name in list(self.images.keys()):
            img = self.images[img_name]
            num_ids = self.patch_creator.num_available_patches(img)
            list_items.extend([[img_name, i] for i in range(num_ids)])
        if self.attr_limit_num_images is not None: # Limit the number of images used
            return list_items[:self.attr_limit_num_images]
        return list_items
    def get_geographic_coords_of_patch(self,name_src_img,patch_id):
        &#34;&#34;&#34;Get the coordinates of the upper left pixel of the patch specified

        Args:
            name_src_img: str, uniq id of the source image
            patch_id: int, id of the patch to get coordinates

        Returns:
            tuple xcoord,ycoord coordinates of the upper left pixel of the patch specified
        &#34;&#34;&#34;
        img = self.images[name_src_img] # read image from the hdf5 file
        transform_array = self.images_infos[name_src_img][&#34;transform&#34;] # get the corresponding transformation array
        transform_array = np.array(transform_array)
        # transfer it into a rasterio AffineTransformation object
        transform = Affine.from_gdal(a=transform_array[0, 0], b=transform_array[0, 1], c=transform_array[0, 2],
                                     d=transform_array[1, 0], e=transform_array[1, 1], f=transform_array[1, 2])
        # Get the position of the upperleft pixel on the global image
        posx,posy = self.patch_creator.get_position_patch(patch_id=patch_id,input_shape=img.shape)
        # Get the corresponding geographical coordinates
        return rowcol(transform,posx,posy)

    def getitem(self, id: Union[int,List[int]]) -&gt; Tuple[np.ndarray, np.ndarray,bool]: # btwn 25 and 50 ms
        &#34;&#34;&#34;Magic method of python called by the object[id] syntax.

        get the patch of global int id id

        Args:
            id: int, global ⚠️ id of the patch

        Returns:
            tuple: input: np.ndarray (shape (grid_size,grid_size,3)), input image for the model ;
                   classif: np.ndarray (shape (num_classes,), classification patch ;
                   reject:  bool, indicate if we need to reject this sample ;
        &#34;&#34;&#34;
        # get the src image id (item: str) and the patch_id (int)
        [item, patch_id] = self.get_all_items()[id] # 0 ns
        # get the source image from the hdf5 cache
        img = self.images[item] # 1ms but 0 most of the time
        # get the source true classification / annotation from the other hdf5 cache
        annotations = self.annotations_labels[item] # 1ms but 0 most of the time
        # get the patch with the selected id for the input image and the annotation
        ## two lines: btwn 21 and 54 ms
        img_patch,reject = self.patch_creator(img, item, patch_id=patch_id) # btwn 10 ms and 50 ms
        annotations_patch,reject = self.patch_creator(annotations, item, patch_id=patch_id) # btwn 10 ms and 30 ms (10 ms most of the time)
        # we reject an image if it contains margins (cf patchcreator)
        # save the resolution of the patch if it has not already been seen
        if (item, patch_id) in self.img_not_seen: # Gpe of 2 lines: ~ 1 ms
            self.save_resolution(item, img_patch) #
        # resize the image at the provided size in the constructor (with the magic method __call__ of the Resizer object
        input = self.attr_resizer(img_patch) # ~ 0 ns most of the time, 1 ms sometimes
        # convert the image to rgb (as required by pytorch): not ncessary the best transformation as we multiply by 3 the amount of data
        input = np.stack((input, input, input), axis=0) # 0 ns most of the time
        # Create the classification label with the proper technic ⚠️⚠️ inheritance
        classif,balance_reject = self.make_classification_label(annotations_patch) # ~ 2 ms
        # As the balancing operation are done in the make_classification_label method, we reject an image
        # if it is rejected due to margins or balancing
        reject = reject and balance_reject
        return input, classif, reject

    def make_classification_label(self, annotations_patch):
        &#34;&#34;&#34;Creates the classification label based on the annotation patch image

        Indicates if we need to reject the patch due to overrepresented class

        Args:
            annotations_patch: np.ndarray 2d containing for each pixel the class of this pixel

        Returns: the classification label

        &#34;&#34;&#34;

        output = np.zeros((len(self.attr_original_class_mapping),),dtype=np.float32) # 0 ns
        for value in self.attr_original_class_mapping.keys(Way.ORIGINAL_WAY): # btwn 1 and 2 ms for the for loop
            # for each class of the original dataset, we put a probability of presence of one if the class is in the patch
            value = int(value)
            #  if the class is in the patch
            if value in annotations_patch:
                output[value] = 1.
        # Check if we need to reject the patch due to overrepresented class
        balance_reject = self.attr_balance.filter(output)
        return output,balance_reject

    def make_patches_of_image(self, name: str):
        &#34;&#34;&#34;Creates and returns all patches of an image

        Args:
            name: uniq str id of the image

        Returns:
            list of list of:

            - patch: np.ndarray
            - classif: np.ndarray classification label as returned by make_classification_label
            - reject: bool reject only based on margins
        &#34;&#34;&#34;
        last_image = np.copy(np.array(self.images[name], dtype=np.float32))
        liste_patches = []
        num_patches = self.patch_creator.num_available_patches(last_image)
        # Create all the patches of input images
        for id in range(num_patches):
            patch,reject = self.patch_creator(last_image, name, patch_id=id, keep=True)
            liste_patches.append([patch])
        annotations = np.array(self.annotations_labels[name], dtype=np.float32)
        for id in range(num_patches):
            patch,reject = self.patch_creator(annotations, name, patch_id=id)
            classif = self.make_classification_label(patch)
            # we ignore balancing rejects
            liste_patches[id].append(classif[0])
            liste_patches[id].append(reject)
        return liste_patches

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;Magic method called when we make len(obj)&#34;&#34;&#34;
        return len(self.get_all_items())

# Tests in DatasetFactory</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="main.src.data.classification.ClassificationPatch.ClassificationPatch"><code class="flex name class">
<span>class <span class="ident">ClassificationPatch</span></span>
<span>(</span><span>patch_creator: <a title="main.src.data.patch_creator.patch_creator0.Patch_creator0" href="../patch_creator/patch_creator0.html#main.src.data.patch_creator.patch_creator0.Patch_creator0">Patch_creator0</a>, input_size: int = None, limit_num_images: int = None, balance='nobalance', margin=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Class that adapt the inputs from the hdf5 file (input image, label image), and manage other objects to create patches,
filteer them.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>patch_creator</code></strong></dt>
<dd>the object of PatchCreator0 class managing patches</dd>
<dt><strong><code>input_size</code></strong></dt>
<dd>the size of the image provided as input to the model ⚠️</dd>
<dt><strong><code>limit_num_images</code></strong></dt>
<dd>limit the number of image in the dataset per epoch (before filtering)</dd>
<dt><strong><code>balance</code></strong></dt>
<dd>str enum {nobalance,balance} indicating the class used to balance images</dd>
<dt><strong><code>margin</code></strong></dt>
<dd>opt int, argument for the BalanceClass1 class</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClassificationPatch(DataSentinel1Segmentation):
    def __init__(self, patch_creator: Patch_creator0, input_size: int = None,
                 limit_num_images: int = None, balance=&#34;nobalance&#34;,margin=None):
        &#34;&#34;&#34;Class that adapt the inputs from the hdf5 file (input image, label image), and manage other objects to create patches,
        filteer them.

        Args:
            patch_creator: the object of PatchCreator0 class managing patches
            input_size: the size of the image provided as input to the model ⚠️
            limit_num_images: limit the number of image in the dataset per epoch (before filtering)
            balance: str enum {nobalance,balance} indicating the class used to balance images
            margin: opt int, argument for the BalanceClass1 class
        &#34;&#34;&#34;
        self.attr_name = self.__class__.__name__ # save the name of the class used for reproductibility purposes
        self.patch_creator = patch_creator
        self.attr_limit_num_images = limit_num_images
        self.attr_resizer = Resizer(out_size_w=input_size)
        super(ClassificationPatch, self).__init__(limit_num_images, input_size=input_size)
        self.attr_global_name = &#34;dataset&#34;
        if balance == &#34;nobalance&#34;:
            self.attr_balance = NoBalance()
        elif balance == &#34;balanceclasses1&#34;:
            # see class DataSentinel1Segmentation for documentation on attr_class_mapping storage and access to values
            self.attr_balance = BalanceClasses1(classes_indexes=self.attr_class_mapping.keys(Way.ORIGINAL_WAY),
                                                margin=margin)


    @lru_cache(maxsize=1)
    def get_all_items(self):
        &#34;&#34;&#34;List available original images available in the dataset (hdf5 file)
        the :lru_cache(maxsize=1) allow to compute it only one time and store the result in a cache

        Allow to limit the number of original image used in the dataset

        Returns: list of list of str,int: [[img_uniq_id,id_patch],...]

        &#34;&#34;&#34;
        list_items = []
        for img_name in list(self.images.keys()):
            img = self.images[img_name]
            num_ids = self.patch_creator.num_available_patches(img)
            list_items.extend([[img_name, i] for i in range(num_ids)])
        if self.attr_limit_num_images is not None: # Limit the number of images used
            return list_items[:self.attr_limit_num_images]
        return list_items
    def get_geographic_coords_of_patch(self,name_src_img,patch_id):
        &#34;&#34;&#34;Get the coordinates of the upper left pixel of the patch specified

        Args:
            name_src_img: str, uniq id of the source image
            patch_id: int, id of the patch to get coordinates

        Returns:
            tuple xcoord,ycoord coordinates of the upper left pixel of the patch specified
        &#34;&#34;&#34;
        img = self.images[name_src_img] # read image from the hdf5 file
        transform_array = self.images_infos[name_src_img][&#34;transform&#34;] # get the corresponding transformation array
        transform_array = np.array(transform_array)
        # transfer it into a rasterio AffineTransformation object
        transform = Affine.from_gdal(a=transform_array[0, 0], b=transform_array[0, 1], c=transform_array[0, 2],
                                     d=transform_array[1, 0], e=transform_array[1, 1], f=transform_array[1, 2])
        # Get the position of the upperleft pixel on the global image
        posx,posy = self.patch_creator.get_position_patch(patch_id=patch_id,input_shape=img.shape)
        # Get the corresponding geographical coordinates
        return rowcol(transform,posx,posy)

    def getitem(self, id: Union[int,List[int]]) -&gt; Tuple[np.ndarray, np.ndarray,bool]: # btwn 25 and 50 ms
        &#34;&#34;&#34;Magic method of python called by the object[id] syntax.

        get the patch of global int id id

        Args:
            id: int, global ⚠️ id of the patch

        Returns:
            tuple: input: np.ndarray (shape (grid_size,grid_size,3)), input image for the model ;
                   classif: np.ndarray (shape (num_classes,), classification patch ;
                   reject:  bool, indicate if we need to reject this sample ;
        &#34;&#34;&#34;
        # get the src image id (item: str) and the patch_id (int)
        [item, patch_id] = self.get_all_items()[id] # 0 ns
        # get the source image from the hdf5 cache
        img = self.images[item] # 1ms but 0 most of the time
        # get the source true classification / annotation from the other hdf5 cache
        annotations = self.annotations_labels[item] # 1ms but 0 most of the time
        # get the patch with the selected id for the input image and the annotation
        ## two lines: btwn 21 and 54 ms
        img_patch,reject = self.patch_creator(img, item, patch_id=patch_id) # btwn 10 ms and 50 ms
        annotations_patch,reject = self.patch_creator(annotations, item, patch_id=patch_id) # btwn 10 ms and 30 ms (10 ms most of the time)
        # we reject an image if it contains margins (cf patchcreator)
        # save the resolution of the patch if it has not already been seen
        if (item, patch_id) in self.img_not_seen: # Gpe of 2 lines: ~ 1 ms
            self.save_resolution(item, img_patch) #
        # resize the image at the provided size in the constructor (with the magic method __call__ of the Resizer object
        input = self.attr_resizer(img_patch) # ~ 0 ns most of the time, 1 ms sometimes
        # convert the image to rgb (as required by pytorch): not ncessary the best transformation as we multiply by 3 the amount of data
        input = np.stack((input, input, input), axis=0) # 0 ns most of the time
        # Create the classification label with the proper technic ⚠️⚠️ inheritance
        classif,balance_reject = self.make_classification_label(annotations_patch) # ~ 2 ms
        # As the balancing operation are done in the make_classification_label method, we reject an image
        # if it is rejected due to margins or balancing
        reject = reject and balance_reject
        return input, classif, reject

    def make_classification_label(self, annotations_patch):
        &#34;&#34;&#34;Creates the classification label based on the annotation patch image

        Indicates if we need to reject the patch due to overrepresented class

        Args:
            annotations_patch: np.ndarray 2d containing for each pixel the class of this pixel

        Returns: the classification label

        &#34;&#34;&#34;

        output = np.zeros((len(self.attr_original_class_mapping),),dtype=np.float32) # 0 ns
        for value in self.attr_original_class_mapping.keys(Way.ORIGINAL_WAY): # btwn 1 and 2 ms for the for loop
            # for each class of the original dataset, we put a probability of presence of one if the class is in the patch
            value = int(value)
            #  if the class is in the patch
            if value in annotations_patch:
                output[value] = 1.
        # Check if we need to reject the patch due to overrepresented class
        balance_reject = self.attr_balance.filter(output)
        return output,balance_reject

    def make_patches_of_image(self, name: str):
        &#34;&#34;&#34;Creates and returns all patches of an image

        Args:
            name: uniq str id of the image

        Returns:
            list of list of:

            - patch: np.ndarray
            - classif: np.ndarray classification label as returned by make_classification_label
            - reject: bool reject only based on margins
        &#34;&#34;&#34;
        last_image = np.copy(np.array(self.images[name], dtype=np.float32))
        liste_patches = []
        num_patches = self.patch_creator.num_available_patches(last_image)
        # Create all the patches of input images
        for id in range(num_patches):
            patch,reject = self.patch_creator(last_image, name, patch_id=id, keep=True)
            liste_patches.append([patch])
        annotations = np.array(self.annotations_labels[name], dtype=np.float32)
        for id in range(num_patches):
            patch,reject = self.patch_creator(annotations, name, patch_id=id)
            classif = self.make_classification_label(patch)
            # we ignore balancing rejects
            liste_patches[id].append(classif[0])
            liste_patches[id].append(reject)
        return liste_patches

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;Magic method called when we make len(obj)&#34;&#34;&#34;
        return len(self.get_all_items())</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="main.src.data.segmentation.DataSentinel1Segmentation.DataSentinel1Segmentation" href="../segmentation/DataSentinel1Segmentation.html#main.src.data.segmentation.DataSentinel1Segmentation.DataSentinel1Segmentation">DataSentinel1Segmentation</a></li>
<li><a title="main.src.param_savers.BaseClass.BaseClass" href="../../param_savers/BaseClass.html#main.src.param_savers.BaseClass.BaseClass">BaseClass</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="main.src.data.classification.ClassificationPatch1.ClassificationPatch1" href="ClassificationPatch1.html#main.src.data.classification.ClassificationPatch1.ClassificationPatch1">ClassificationPatch1</a></li>
<li><a title="main.src.data.classification.ClassificationPatch2.ClassificationPatch2" href="ClassificationPatch2.html#main.src.data.classification.ClassificationPatch2.ClassificationPatch2">ClassificationPatch2</a></li>
<li><a title="main.src.data.classification.VectorizedClassificationPatch.VectorizzedClassificationPatch" href="VectorizedClassificationPatch.html#main.src.data.classification.VectorizedClassificationPatch.VectorizzedClassificationPatch">VectorizzedClassificationPatch</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="main.src.data.classification.ClassificationPatch.ClassificationPatch.get_all_items"><code class="name flex">
<span>def <span class="ident">get_all_items</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>List available original images available in the dataset (hdf5 file)
the :lru_cache(maxsize=1) allow to compute it only one time and store the result in a cache</p>
<p>Allow to limit the number of original image used in the dataset</p>
<p>Returns: list of list of str,int: [[img_uniq_id,id_patch],&hellip;]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@lru_cache(maxsize=1)
def get_all_items(self):
    &#34;&#34;&#34;List available original images available in the dataset (hdf5 file)
    the :lru_cache(maxsize=1) allow to compute it only one time and store the result in a cache

    Allow to limit the number of original image used in the dataset

    Returns: list of list of str,int: [[img_uniq_id,id_patch],...]

    &#34;&#34;&#34;
    list_items = []
    for img_name in list(self.images.keys()):
        img = self.images[img_name]
        num_ids = self.patch_creator.num_available_patches(img)
        list_items.extend([[img_name, i] for i in range(num_ids)])
    if self.attr_limit_num_images is not None: # Limit the number of images used
        return list_items[:self.attr_limit_num_images]
    return list_items</code></pre>
</details>
</dd>
<dt id="main.src.data.classification.ClassificationPatch.ClassificationPatch.get_geographic_coords_of_patch"><code class="name flex">
<span>def <span class="ident">get_geographic_coords_of_patch</span></span>(<span>self, name_src_img, patch_id)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the coordinates of the upper left pixel of the patch specified</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name_src_img</code></strong></dt>
<dd>str, uniq id of the source image</dd>
<dt><strong><code>patch_id</code></strong></dt>
<dd>int, id of the patch to get coordinates</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>tuple xcoord,ycoord coordinates of the upper left pixel of the patch specified</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_geographic_coords_of_patch(self,name_src_img,patch_id):
    &#34;&#34;&#34;Get the coordinates of the upper left pixel of the patch specified

    Args:
        name_src_img: str, uniq id of the source image
        patch_id: int, id of the patch to get coordinates

    Returns:
        tuple xcoord,ycoord coordinates of the upper left pixel of the patch specified
    &#34;&#34;&#34;
    img = self.images[name_src_img] # read image from the hdf5 file
    transform_array = self.images_infos[name_src_img][&#34;transform&#34;] # get the corresponding transformation array
    transform_array = np.array(transform_array)
    # transfer it into a rasterio AffineTransformation object
    transform = Affine.from_gdal(a=transform_array[0, 0], b=transform_array[0, 1], c=transform_array[0, 2],
                                 d=transform_array[1, 0], e=transform_array[1, 1], f=transform_array[1, 2])
    # Get the position of the upperleft pixel on the global image
    posx,posy = self.patch_creator.get_position_patch(patch_id=patch_id,input_shape=img.shape)
    # Get the corresponding geographical coordinates
    return rowcol(transform,posx,posy)</code></pre>
</details>
</dd>
<dt id="main.src.data.classification.ClassificationPatch.ClassificationPatch.getitem"><code class="name flex">
<span>def <span class="ident">getitem</span></span>(<span>self, id: Union[int, List[int]]) ‑> Tuple[numpy.ndarray, numpy.ndarray, bool]</span>
</code></dt>
<dd>
<div class="desc"><p>Magic method of python called by the object[id] syntax.</p>
<p>get the patch of global int id id</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>id</code></strong></dt>
<dd>int, global ⚠️ id of the patch</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>input: np.ndarray (shape (grid_size,grid_size,3)), input image for the model ;
classif: np.ndarray (shape (num_classes,), classification patch ;
reject:
bool, indicate if we need to reject this sample ;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getitem(self, id: Union[int,List[int]]) -&gt; Tuple[np.ndarray, np.ndarray,bool]: # btwn 25 and 50 ms
    &#34;&#34;&#34;Magic method of python called by the object[id] syntax.

    get the patch of global int id id

    Args:
        id: int, global ⚠️ id of the patch

    Returns:
        tuple: input: np.ndarray (shape (grid_size,grid_size,3)), input image for the model ;
               classif: np.ndarray (shape (num_classes,), classification patch ;
               reject:  bool, indicate if we need to reject this sample ;
    &#34;&#34;&#34;
    # get the src image id (item: str) and the patch_id (int)
    [item, patch_id] = self.get_all_items()[id] # 0 ns
    # get the source image from the hdf5 cache
    img = self.images[item] # 1ms but 0 most of the time
    # get the source true classification / annotation from the other hdf5 cache
    annotations = self.annotations_labels[item] # 1ms but 0 most of the time
    # get the patch with the selected id for the input image and the annotation
    ## two lines: btwn 21 and 54 ms
    img_patch,reject = self.patch_creator(img, item, patch_id=patch_id) # btwn 10 ms and 50 ms
    annotations_patch,reject = self.patch_creator(annotations, item, patch_id=patch_id) # btwn 10 ms and 30 ms (10 ms most of the time)
    # we reject an image if it contains margins (cf patchcreator)
    # save the resolution of the patch if it has not already been seen
    if (item, patch_id) in self.img_not_seen: # Gpe of 2 lines: ~ 1 ms
        self.save_resolution(item, img_patch) #
    # resize the image at the provided size in the constructor (with the magic method __call__ of the Resizer object
    input = self.attr_resizer(img_patch) # ~ 0 ns most of the time, 1 ms sometimes
    # convert the image to rgb (as required by pytorch): not ncessary the best transformation as we multiply by 3 the amount of data
    input = np.stack((input, input, input), axis=0) # 0 ns most of the time
    # Create the classification label with the proper technic ⚠️⚠️ inheritance
    classif,balance_reject = self.make_classification_label(annotations_patch) # ~ 2 ms
    # As the balancing operation are done in the make_classification_label method, we reject an image
    # if it is rejected due to margins or balancing
    reject = reject and balance_reject
    return input, classif, reject</code></pre>
</details>
</dd>
<dt id="main.src.data.classification.ClassificationPatch.ClassificationPatch.make_classification_label"><code class="name flex">
<span>def <span class="ident">make_classification_label</span></span>(<span>self, annotations_patch)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates the classification label based on the annotation patch image</p>
<p>Indicates if we need to reject the patch due to overrepresented class</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>annotations_patch</code></strong></dt>
<dd>np.ndarray 2d containing for each pixel the class of this pixel</dd>
</dl>
<p>Returns: the classification label</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_classification_label(self, annotations_patch):
    &#34;&#34;&#34;Creates the classification label based on the annotation patch image

    Indicates if we need to reject the patch due to overrepresented class

    Args:
        annotations_patch: np.ndarray 2d containing for each pixel the class of this pixel

    Returns: the classification label

    &#34;&#34;&#34;

    output = np.zeros((len(self.attr_original_class_mapping),),dtype=np.float32) # 0 ns
    for value in self.attr_original_class_mapping.keys(Way.ORIGINAL_WAY): # btwn 1 and 2 ms for the for loop
        # for each class of the original dataset, we put a probability of presence of one if the class is in the patch
        value = int(value)
        #  if the class is in the patch
        if value in annotations_patch:
            output[value] = 1.
    # Check if we need to reject the patch due to overrepresented class
    balance_reject = self.attr_balance.filter(output)
    return output,balance_reject</code></pre>
</details>
</dd>
<dt id="main.src.data.classification.ClassificationPatch.ClassificationPatch.make_patches_of_image"><code class="name flex">
<span>def <span class="ident">make_patches_of_image</span></span>(<span>self, name: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates and returns all patches of an image</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>uniq str id of the image</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>list of list of:</p>
<ul>
<li>patch: np.ndarray</li>
<li>classif: np.ndarray classification label as returned by make_classification_label</li>
<li>reject: bool reject only based on margins</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_patches_of_image(self, name: str):
    &#34;&#34;&#34;Creates and returns all patches of an image

    Args:
        name: uniq str id of the image

    Returns:
        list of list of:

        - patch: np.ndarray
        - classif: np.ndarray classification label as returned by make_classification_label
        - reject: bool reject only based on margins
    &#34;&#34;&#34;
    last_image = np.copy(np.array(self.images[name], dtype=np.float32))
    liste_patches = []
    num_patches = self.patch_creator.num_available_patches(last_image)
    # Create all the patches of input images
    for id in range(num_patches):
        patch,reject = self.patch_creator(last_image, name, patch_id=id, keep=True)
        liste_patches.append([patch])
    annotations = np.array(self.annotations_labels[name], dtype=np.float32)
    for id in range(num_patches):
        patch,reject = self.patch_creator(annotations, name, patch_id=id)
        classif = self.make_classification_label(patch)
        # we ignore balancing rejects
        liste_patches[id].append(classif[0])
        liste_patches[id].append(reject)
    return liste_patches</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="main.src.data.segmentation.DataSentinel1Segmentation.DataSentinel1Segmentation" href="../segmentation/DataSentinel1Segmentation.html#main.src.data.segmentation.DataSentinel1Segmentation.DataSentinel1Segmentation">DataSentinel1Segmentation</a></b></code>:
<ul class="hlist">
<li><code><a title="main.src.data.segmentation.DataSentinel1Segmentation.DataSentinel1Segmentation.close" href="../segmentation/DataSentinel1Segmentation.html#main.src.data.segmentation.DataSentinel1Segmentation.DataSentinel1Segmentation.close">close</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="main.src.data.classification" href="index.html">main.src.data.classification</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="main.src.data.classification.ClassificationPatch.ClassificationPatch" href="#main.src.data.classification.ClassificationPatch.ClassificationPatch">ClassificationPatch</a></code></h4>
<ul class="">
<li><code><a title="main.src.data.classification.ClassificationPatch.ClassificationPatch.get_all_items" href="#main.src.data.classification.ClassificationPatch.ClassificationPatch.get_all_items">get_all_items</a></code></li>
<li><code><a title="main.src.data.classification.ClassificationPatch.ClassificationPatch.get_geographic_coords_of_patch" href="#main.src.data.classification.ClassificationPatch.ClassificationPatch.get_geographic_coords_of_patch">get_geographic_coords_of_patch</a></code></li>
<li><code><a title="main.src.data.classification.ClassificationPatch.ClassificationPatch.getitem" href="#main.src.data.classification.ClassificationPatch.ClassificationPatch.getitem">getitem</a></code></li>
<li><code><a title="main.src.data.classification.ClassificationPatch.ClassificationPatch.make_classification_label" href="#main.src.data.classification.ClassificationPatch.ClassificationPatch.make_classification_label">make_classification_label</a></code></li>
<li><code><a title="main.src.data.classification.ClassificationPatch.ClassificationPatch.make_patches_of_image" href="#main.src.data.classification.ClassificationPatch.ClassificationPatch.make_patches_of_image">make_patches_of_image</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>