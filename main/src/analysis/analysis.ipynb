{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os, re\n",
    "from main.FolderInfos import FolderInfos\n",
    "from main.src.models.ModelFactory import ModelFactory\n",
    "\n",
    "FolderInfos.init(test_without_data=True)\n",
    "list_dataout_folders = os.listdir(FolderInfos.data_folder)\n",
    "list_folders = []\n",
    "for f in list_dataout_folders:\n",
    "    full_path = FolderInfos.data_folder+f\n",
    "    files = os.listdir(full_path)\n",
    "    files_to_contain = [[re.compile(r\".+_parameters.json$\"),False]]\n",
    "    for file in files:\n",
    "        for i,check in enumerate(files_to_contain):\n",
    "            if check[0].match(file):\n",
    "                files_to_contain[i][1] = True\n",
    "        if len(list(filter(lambda x:x[1] is False,files_to_contain))) == 0: # If all of the required files are in the folder\n",
    "            list_folders.append(f)\n",
    "            break\n",
    "\n",
    "import ipywidgets as widgets\n",
    "for f in list_folders:\n",
    "    widgets.ToggleButton(\n",
    "        value=False,\n",
    "        description=f,\n",
    "        disabled=False,\n",
    "        button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='',\n",
    "        icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    "    )\n",
    "selected_folder = list_folders\n",
    "import json\n",
    "global_dict = {}\n",
    "for f in selected_folder:\n",
    "    full_path = FolderInfos.data_folder+f+FolderInfos.separator\n",
    "    with open(f\"{full_path}{f}parameters.json\") as fp:\n",
    "        global_dict[f] = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(VBox(children=(Checkbox(value=False, description='tr_loss'), Checkbox(value=False, description=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3d30b327a46453989c3ba4c31a8d4cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import Checkbox, VBox, IntSlider, HBox, IntText, FloatText\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import main.src.analysis.tools as tls\n",
    "\n",
    "def loss_access(x,mode):\n",
    "    return x[\"training\"][f\"{mode}_loss\"]\n",
    "def metrics_access(x,name,mode):\n",
    "    return x[\"metrics\"][\"attr_list_metrics\"][name][f\"{mode}_values\"]\n",
    "\n",
    "dico_loss = {\"tr_loss\":lambda x:loss_access(x,mode=\"tr\"),\"valid_loss\":lambda x:loss_access(x,mode=\"valid\")}\n",
    "\n",
    "dico_accuracy = {\"tr_accuracy_classification-0.1\":lambda x:metrics_access(x,\"accuracy_classification-0.1\",\"tr\"),\n",
    "                 \"valid_accuracy_classification-0.1\":lambda x:metrics_access(x,\"accuracy_classification-0.1\",\"valid\"),\n",
    "                 \"tr_accuracy_classification-0.25\":lambda x:metrics_access(x,\"accuracy_classification-0.25\",\"tr\"),\n",
    "                 \"valid_accuracy_classification-0.25\":lambda x:metrics_access(x,\"accuracy_classification-0.25\",\"valid\"),\n",
    "                 }\n",
    "dico_mae = {\"tr_mae\":lambda x:metrics_access(x,\"mae\",\"tr\"),\n",
    "            \"valid_mae\":lambda x:metrics_access(x,\"mae\",\"valid\")\n",
    "            }\n",
    "list_access_functions = {**dico_loss,\n",
    "                         **dico_accuracy,\n",
    "                         **dico_mae\n",
    "                         }\n",
    "list_values_names_availables = []\n",
    "for name,f in list_access_functions.items():\n",
    "    try:\n",
    "        for dico in global_dict.values():\n",
    "            f(dico)\n",
    "        list_values_names_availables.append(name)\n",
    "    except Exception():\n",
    "        pass\n",
    "filters = None\n",
    "log_scale = None\n",
    "box = None\n",
    "from IPython.display import display,clear_output\n",
    "def actualize(v):\n",
    "    import numpy as np\n",
    "    global box\n",
    "    clear_output()\n",
    "    list_values_names_availables_filtered = []\n",
    "    if filters is not None:\n",
    "        for metric,widg in filters.items():\n",
    "            if widg.value is True:\n",
    "                list_values_names_availables_filtered.append(metric)\n",
    "    list_values_names_availables = list_values_names_availables_filtered\n",
    "    liste_values = []\n",
    "    min_val,max_val = 1000000,-1000000\n",
    "    max_length = 0\n",
    "    for metric_name in list_values_names_availables:\n",
    "        for f in global_dict.keys():\n",
    "            batch_size = global_dict[f][\"data\"][\"batch_size\"] * global_dict[f][\"data\"][\"eval_step\"] if \"valid\" in metric_name else global_dict[f][\"data\"][\"batch_size\"]\n",
    "            window = int(window_mean.value/batch_size)\n",
    "            v = tls.moving_mean(list_access_functions[metric_name](global_dict[f]),window=window)\n",
    "            x = np.arange(0,len(v)) * batch_size\n",
    "\n",
    "            max_length = max(np.max(x),max_length)\n",
    "            min_val = min(min_val,np.min(v[5:]))\n",
    "            max_val = max(max_val,np.max(v[5:]))\n",
    "            x = pd.Series(x)\n",
    "            v = pd.Series(v)\n",
    "            graph = go.Scatter(x=x,y=v,mode='lines',name=f\"{metric_name} {f}\",hovertemplate='Sample n°: %{x}'+f'<br>{metric_name}:'+' %{y}')\n",
    "            liste_values.append(graph)\n",
    "    # print(min_val,max_val)\n",
    "    import numpy as np\n",
    "    epoch_size = max(map(lambda x:x[\"data\"][\"dataset\"][\"attr_length_dataset\"],global_dict.values()))\n",
    "\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=liste_values,\n",
    "        layout=go.Layout(\n",
    "            title=go.layout.Title(text=\"\"),\n",
    "            xaxis_title=\"Number of samples processed\",\n",
    "            yaxis_title=f\"Values\",\n",
    "            legend=dict(\n",
    "                orientation=\"h\",\n",
    "                yanchor=\"bottom\",\n",
    "                y=1.02,\n",
    "                xanchor=\"right\",\n",
    "                x=1\n",
    "            ),\n",
    "            yaxis={'tickformat':'.1e',\n",
    "\n",
    "                   },\n",
    "\n",
    "\n",
    "        )\n",
    "    )\n",
    "    if log_scale is not None and log_scale.value is True:\n",
    "        fig.update_yaxes(type=\"log\")\n",
    "    fig.show()\n",
    "    if box is not None:\n",
    "        display(box)\n",
    "    return min_val,max_val\n",
    "\n",
    "window_mean = IntText(\n",
    "    value=100,\n",
    "    description='Mean window:',\n",
    "    disabled=False\n",
    ")\n",
    "mini,maxi = actualize(None)\n",
    "clear_output()\n",
    "log_scale = Checkbox(False,description=\"y_log\")\n",
    "filters = {name:Checkbox(False,description=name) for name in list_values_names_availables}\n",
    "list_widgets = [*filters.values(),log_scale,window_mean]\n",
    "box1 = VBox(list(filters.values()))\n",
    "box = HBox([box1,VBox([log_scale,window_mean])])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for w in list_widgets:\n",
    "    w.observe(actualize)\n",
    "box"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Dropdown(description='Folder to vizualize result', options=('2021-06-10_11h31min34s_', '2021-06-11_12h30min51s…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6e83d82f57d47928eb77d9250b12bc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Dropdown\n",
    "\n",
    "choice_folder = Dropdown(\n",
    "    options=selected_folder,\n",
    "    value=selected_folder[0],\n",
    "    description='Folder to vizualize result',\n",
    "    disabled=False,\n",
    "         )\n",
    "display(choice_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n",
      "(1000, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n",
      "(1000, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n",
      "(1000, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n",
      "(1000, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n",
      "(1000, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n",
      "(1000, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n",
      "(1000, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n",
      "(1000, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n",
      "(1000, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n",
      "(600, 1000, 3) (10600, 18441, 3) (1000, 1000, 3) 1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (1000,1000,3) into shape (600,1000,3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-6-00a1eac7eb46>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{folder}{choice_folder.value}_model_epoch-{epoch}_it-{iteration}.pt\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m \u001B[0marray_overlay\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrgb_overlay\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_img\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"027481_0319CB_0EB7\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mblending_factor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.5\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\projets\\detection_nappe_hydrocarbures_inria_cefrem\\main\\src\\analysis\\tools.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, name_img, model, blending_factor, device)\u001B[0m\n\u001B[0;32m     46\u001B[0m             if overlay_true[pos_x:pos_x+self.dataset.attr_patch_creator.attr_grid_size_px,\n\u001B[0;32m     47\u001B[0m                     \u001B[0mpos_y\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mpos_y\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mattr_patch_creator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mattr_grid_size_px\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m                     :].shape[0] != self.dataset.attr_patch_creator.attr_grid_size_px:\n\u001B[0m\u001B[0;32m     49\u001B[0m                 \u001B[0ms\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m             overlay_true[pos_x:pos_x+self.dataset.attr_patch_creator.attr_grid_size_px,\n",
      "\u001B[1;31mValueError\u001B[0m: could not broadcast input array from shape (1000,1000,3) into shape (600,1000,3)"
     ]
    }
   ],
   "source": [
    "from main.src.analysis.tools import RGB_Overlay_Patch\n",
    "from main.src.models.ModelFactory import ModelFactory\n",
    "folder = FolderInfos.data_folder+choice_folder.value+FolderInfos.separator\n",
    "with open(folder+choice_folder.value+\"parameters.json\",\"r\") as fp:\n",
    "    dico = json.load(fp)\n",
    "\n",
    "rgb_overlay = RGB_Overlay_Patch(usage_type=\"classification\",patch_creator=\"fixed_px\",grid_size=dico[\"data\"][\"dataset\"][\"attr_patch_creator\"][\"attr_grid_size_px\"],input_size=dico[\"data\"][\"dataset\"][\"attr_dataset\"][\"attr_resizer\"][\"attr_out_size_w\"])\n",
    "epoch = 0\n",
    "iteration = 6080\n",
    "import torch\n",
    "device = torch.device(\"cuda\")\n",
    "model = ModelFactory(model_name=dico[\"model\"][\"attr_model_name\"],num_classes=dico[\"model\"][\"attr_num_classes\"])()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(f\"{folder}{choice_folder.value}_model_epoch-{epoch}_it-{iteration}.pt\"))\n",
    "array_overlay = rgb_overlay(name_img=\"027481_0319CB_0EB7\",model=model,blending_factor=0.5,device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f84d40f0",
   "language": "python",
   "display_name": "PyCharm (detection_nappe_hydrocarbures_inria_cefrem)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}